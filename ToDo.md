# ToDo
<!-- templates -->
<!-- ## 日付     -->
<!-- ## 目標     -->
<!-- ## 内容     -->
<!-- ## 次の目標 -->
## 思い付き
- 原画像のノイズ除去後、セマセグ推論を行う。  
    ground truth(セマセグ画像)との比較を行い、重みの更新を行う。
- カメラの姿勢位置ずれの再現方法を調査(前処理のための)
- 環境変動にロバストなモデルを作成するための処理ではなく、環境変動をなるべく抑えるための前処理

## 参考サイト
- http://www.renom.jp/ja/index.html
- https://qiita.com/jiny2001/items/a33693d8b2455059f457
- http://keiku.hatenablog.jp/entry/2018/07/22/220158
- http://ni4muraano.hatenablog.com/entry/2017/08/10/101053

## 2018/08/03
## 目標
- [ ] enhancenet
- [x] ノイズ除去CNN

## 内容
- enhancenet  
    pre-trained modelの入手  
- DNCNN(Denoising Convolutional Neural Network)  
    畳み込み、Batchnormalization、活性化関数Reluを重ね、最後だけTanhを使う
- Unetによる人の学習とセグメンテーション
- 

## 次の目標
- カメラの姿勢位置ずれの再現方法を調査(前処理のための)
- 環境変動にロバストなモデルを作成するための処理ではなく、環境変動をなるべく抑えるための前処理

## 2018/08/02
## 目標
- [x] kerasでモデルを組み、学習と可視化
- [x] DFT, DCTの差異
## 内容
- 結局のところ、DFTもDCTも画像を周波数の集合に分離するような変換を行っているのだが、
    その変換を行う計算式が、DFTでは少々ややこしい。 複素数の扱いが必要になるためである。
    そのため、DCTが画像圧縮では用いられる。DCTでは、元の画像を立てよ子とも座標軸に対象に折り返し、偶関数にしたものの離散フーリエに相当する。  

- graphvizインストール完了
- 超解像技術、EnhanceNet-PATについて  
    ピクセル数を4*4倍にする、それ以上については触れられていない  

- Pixel Recursive Super Resolutionについて  
    8*8pixelから、32ピクセルの画像を生成。
    2つのNNトレーニングによって画像の予測を行う。一つは似たような高解像度イメージを圧縮したﾃﾞｰﾀと、8*8サンプルを比較して色をチェックするconditioning networkで、もう一つはPixelCNNを用いて高解像の詳細部分を追加するprior networkである。  
    この2つのNNを組み合わせることで、予測画像を作成している。

- SRCNNについて  
    入力画像をバイキュービックで拡大したのちに、CNNを通して高周波成分を推定、生成し付け加えることで、超解像を行う。
- のちのち  
    DNNによる画像認識技術に食わせるための学習データを選定、前処理(ノイズリダクション、エンハンス等)  
- アンシャープマスキングがopencvだとうまくいかない(カラーだと、入力画像-ガウス画像の部分で少し変な色が出る)

## 次の目標
- ノイズありでの先鋭化手法を考える(エッジ検出と、スパース性の利用)
- EnhanceNet-PATによる超解像はどれほどの力なのか
- 渡邊さんにデュアルブートの方法聞く
- レイヤー名のリセット方法

## 2018/07/31
## 目標
- [ ] CNNの派生形を調査
- [x] kerasによるモデル作成
- [ ] 研修とセミナーについて
- [x] 支払依頼など
## 内容
### CNN派生形
- FCN(全層畳み込み)
    CNNの最後の全結合層を畳み込み層に置き換えるというもの。  
    全結合層を用いると、出力は分類クラスであるが、畳み込み層を用いることで、
    出力を二次元マップにできる。  
    この手法(二次元画像からpredictionマップを得る手法)によって得られる利点は、
    - 任意のサイズの画像の入力が可能になる(全結合層に入力するサイズは指定される)
    - conv層の被りがなくなる(よくわからない)
    の2つのメリットが得られる。  
    ただし、ストライドが2以上のフィルタを用いた場合には、解像度が落ちてしまうというデメリットも生じる。  
    対策として、Deconvolution層によって解像度の拡大を行っている。  
    スキップアーキテクチャ  
    CNNの畳み込み層の下位レイヤー(ローカルな特徴マップ)を上位レイヤー(高次の特徴マップ)と結合させて精度の向上を図ったもの(誤差逆伝搬にもいい影響あり)  
    Deconvolutionとは、convolution後の特徴マップを引き延ばして(空白を間に入れる)カーネルを適用し、新たな特徴マップを得る手法  

- Dilated/Atrous畳み込み  
    普通の畳み込みは、カーネルはそれぞれ隣り合うピクセルを参照しているが、
    Dilated畳み込みでは、1つ開けて隣のピクセルを参照するなど、より広い範囲を参照しての畳み込みを行う。  
    - CRF(条件付き確率場)後処理
- R-CNN(Regionsなのでリカレントでない、あくまで空間)
    入力画像から、物体が映っている領域の候補を抽出(色や濃淡勾配などの特徴が類似している領域)し、CNNのインプットに合うようにリサイズし、
    それぞれの領域に対してCNNで特徴量を計算し、分類する。  
- SPP(spatial pyramid pooling)
    異なるサイズの入力に対して、出力サイズを一定にするプーリング手法  
    画像(特徴マップ)を格子状に1, 4, 16, ...と分割し、その中で、プーリングを行う。
    その後、1+4+16+...と、つなげたベクトルをSPPの出力とする。
    つまり、出力のサイズはピラミッドのサイズとチャンネル数にのみ依存する。

### kerasのモデル作成
- cifar10データセットの認識モデル(畳み込み)
## 次の目標
- wslでGPU認識できたと思ったらできてなかった(重要)
- 現在はSpyderにコードを移して実行している(やや不便)
プロキシの問題でデータセットをダウンロードできない場合の応急処置
import urllib.request
# proxy の設定
proxy_support = urllib.request.ProxyHandler({'http' : 'http://user:pass@10.1.8.72:8080/',
                                             'https': 'https://user:pass@10.1.8.72:8080/'})
opener = urllib.request.build_opener(proxy_support)
urllib.request.install_opener(opener)

## 2018/07/31
## 目標
### vim
- [x] vimでのマークダウンのプレビュー
### python
- [x] kerasのチュートリアルなど進める
## 内容
### bash
- CUDA, CuDNN, Tensorflow, kerasの導入(割としんどかった)
### vim
- :Previmによってクローム上でプレビュー可能に(bashrcいじった)
- previmのプレビュー画面をgithub調に
- Ctrl+j(insertモード)で改行(文の途中であれば、それを無視して下の行から)
### python
- kerasでmnistのチュートリアルというかは2層のモデルの作成、学習と評価の写経

## 次の目標

